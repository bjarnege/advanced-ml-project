{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import vae # file where the architecture etc. of the autoencoder is defined\n",
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {
    "id": "jZv3BDi4Ifgv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# search for gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Traning on\", device)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ib86jczQEKU",
    "outputId": "40293f5d-5017-492f-e168-49de0f01d83c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# definition of hyperparameters\n",
    "batch_size = 16\n",
    "\n",
    "hidden_dim = 300\n",
    "latent_dim = 50\n",
    "\n",
    "lr = 1e-5\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "train_size = 0.9"
   ],
   "outputs": [],
   "metadata": {
    "id": "C6XkcjpQLByN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# preprocessing of the images (already extracted from pdf->old data format)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to load already preprocessed pictures or start new preprocessing\n",
    "try:\n",
    "    with open('../../resource/vae_data/images_tensor_255_200x200.pkl', 'rb') as f:\n",
    "    img_list = pickle.load(f)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    \n",
    "    # List of image formats that can be used\n",
    "    allowed = [\"png\", \"PNG\", \"jpg\", \"JPG\", \"jpeg\", \"JPEG\", \"eps\", \"EPS\"]\n",
    "    img_list = []\n",
    "    load_counter = 0\n",
    "    error_counter = 0\n",
    "    counter = 0\n",
    "\n",
    "    # define path containing your training and test images\n",
    "    directory = [str(i) for i in list(Path(\"./datapics/\").rglob(\"*.*\")) if str(i).split(\".\")[-1] in allowed]\n",
    "\n",
    "    for img_path in tqdm(directory):\n",
    "        counter += 1\n",
    "        try:\n",
    "            \n",
    "            # open image, convert to RGBA and resize to 200x200\n",
    "            image = Image.open(img_path).convert(mode=\"RGBA\").resize((200,200))\n",
    "\n",
    "            img_list.append(image)\n",
    "\n",
    "            load_counter += 1\n",
    "\n",
    "            del image\n",
    "\n",
    "        except:\n",
    "\n",
    "            error_counter += 1\n",
    "\n",
    "    print(str(error_counter) + \" images throw an error while loading\")\n",
    "    print(str(load_counter) + \" images load successfully\")\n",
    "\n",
    "    # safe the results\n",
    "    with open('../../resource/vae_data/images_tensor_255_200x200.pkl', 'wb') as f:\n",
    "        pickle.dump(img_list, f)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "V8dJwvTApgzN",
    "outputId": "8d890545-533c-4db6-8898-2de321e158fb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# split the images into train and test\n",
    "data_train = img_list[:round(len(img_list)*train_size)]\n",
    "data_test = img_list[round(len(img_list)*train_size):]\n",
    "del img_list"
   ],
   "outputs": [],
   "metadata": {
    "id": "UUGtAInuKGUA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# transform the images to tensors and normalize them\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean=[0.5, 0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5, 0.5])])\n",
    "\n",
    "train_dataset = vae.MyDataset(data_train, transform=transform)\n",
    "test_dataset = vae.MyDataset(data_test, transform=transform)"
   ],
   "outputs": [],
   "metadata": {
    "id": "vKCSJms6tRDF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create dataloaders to feed data into the neural network\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, drop_last=True)"
   ],
   "outputs": [],
   "metadata": {
    "id": "zt1gLIvumY0Z"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# test visualization of one image\n",
    "batch_idx, data = next(enumerate(train_loader))\n",
    "plt.imshow(data[9].detach().cpu().view(-1,4, 200,200)[0].permute(1,2,0))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "zMQfsbX8etGd",
    "outputId": "28e7aeaf-72e5-431e-a944-f774730b3340"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# initialization of the models\n",
    "encoder = vae.Encoder(hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "decoder = vae.Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim)\n",
    "\n",
    "model = vae.VAE(Encoder=encoder, Decoder=decoder).to(device)"
   ],
   "outputs": [],
   "metadata": {
    "id": "jbmZ-Nm2P_Aj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#loss function: mse and kld\n",
    "from torch.optim import Adam\n",
    "\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.mse_loss(x, x_hat, reduction='sum')\n",
    "    KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "    loss = reproduction_loss + KLD\n",
    "\n",
    "    return loss, reproduction_loss, KLD"
   ],
   "outputs": [],
   "metadata": {
    "id": "dA5D404WRQRO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optimizer = Adam(model.parameters(), lr=lr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#try to load older training status\n",
    "try:\n",
    "\n",
    "    open_file = open(\"../../resource/vae_data/training_test_history.pkl\", \"rb\")\n",
    "    training_test_history = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "\n",
    "    restored_epoch = max(training_test_history['test_loss']['loss'].keys())\n",
    "    model.load_state_dict(torch.load(f\"../../resource/vae_data/VAE_epoch_{restored_epoch}.pt\", map_location=device))\n",
    "\n",
    "    print(f\"Loaded older training status from epoch {restored_epoch}\")\n",
    "\n",
    "except (FileNotFoundError, ValueError):\n",
    "\n",
    "    training_test_history = {'training_loss': {\"loss\": {}, \"reproduction_loss\": {}, \"KLD\": {}}, 'test_loss': {\"loss\": {}, \"reproduction_loss\": {}, \"KLD\": {}}}\n",
    "\n",
    "    restored_epoch = 0\n",
    "\n",
    "    print(\"Starting Training from scratch.\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWAE1FbMLrk2",
    "outputId": "6dd3ff50-9f3b-48cf-c679-aeddaa9b94fb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# training loop with continous testing\n",
    "print(\"Start training VAE...\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(restored_epoch+1, epochs+1):\n",
    "    \n",
    "    # reset loss to start with new epoch\n",
    "    overall_loss = 0\n",
    "    overall_reproduction_loss = 0\n",
    "    overall_KLD = 0\n",
    "\n",
    "    # iterate over batches\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "        x = data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat, mean, log_var, z = model(x)\n",
    "        loss, reproduction_loss, KLD = loss_function(x, x_hat, mean, log_var)\n",
    "        \n",
    "        overall_loss += loss.item()\n",
    "        overall_reproduction_loss += reproduction_loss.item()\n",
    "        overall_KLD += KLD.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del data\n",
    "        del x\n",
    "        del x_hat\n",
    "    \n",
    "    # safe the training loss values of the epoch\n",
    "    training_test_history['training_loss']['loss'][epoch] = overall_loss / (batch_idx*batch_size)\n",
    "    training_test_history['training_loss']['reproduction_loss'][epoch] = overall_reproduction_loss / (batch_idx*batch_size)\n",
    "    training_test_history['training_loss']['KLD'][epoch] = overall_KLD / (batch_idx*batch_size)\n",
    "\n",
    "    # start continous testing\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # reset loss to start with testing new epoch\n",
    "        overall_test_loss = 0\n",
    "        overall_test_reproduction_loss = 0\n",
    "        overall_test_KLD = 0\n",
    "        \n",
    "        # iterate over test batches\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "\n",
    "            x = data.to(device)\n",
    "\n",
    "            x_hat, mean, log_var, z = model(x)\n",
    "            test_loss, test_reproduction_loss, test_KLD = loss_function(x, x_hat, mean, log_var)\n",
    "\n",
    "            overall_test_loss += test_loss.item()\n",
    "            overall_test_reproduction_loss += test_reproduction_loss.item()\n",
    "            overall_test_KLD += test_KLD.item()\n",
    "\n",
    "            del data\n",
    "            del x\n",
    "            del x_hat\n",
    "    \n",
    "    # safe the test loss values of the epoch\n",
    "    training_test_history['test_loss']['loss'][epoch] = overall_test_loss / (batch_idx*batch_size)\n",
    "    training_test_history['test_loss']['reproduction_loss'][epoch] = overall_test_reproduction_loss / (batch_idx*batch_size)\n",
    "    training_test_history['test_loss']['KLD'][epoch] = overall_test_KLD / (batch_idx*batch_size)\n",
    "    \n",
    "    # end the testing mode\n",
    "    model.train()\n",
    "\n",
    "    # save every model and training history\n",
    "    torch.save(model.state_dict(),f'../../resource/vae_data/VAE_epoch_{epoch}.pt')\n",
    "\n",
    "    open_file = open(f\"../../resource/vae_data/training_test_history.pkl\", \"wb\")\n",
    "    pickle.dump(training_test_history, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "    print(f\"\\tEpoch {epoch} complete! \\tAverage Train Loss:  {training_test_history['training_loss']['loss'][epoch]} (Best Epoch: {min(training_test_history['training_loss']['loss'], key=training_test_history['training_loss']['loss'].get)}) \\t\\tAverage Test Loss: {training_test_history['test_loss']['loss'][epoch]} (Best Epoch: {min(training_test_history['test_loss']['loss'], key=training_test_history['test_loss']['loss'].get)})\")\n",
    "    print(\"-\"*30)\n",
    "\n",
    "    \n",
    "print(\"Finish!\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqSjKDa4Rxys",
    "outputId": "08bbc3d3-4e78-41b5-da8b-2d0ee7fdeaed"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test by generating a new image"
   ],
   "metadata": {
    "id": "csu7qYljWsjh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sample random images from latent space\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(1, latent_dim).to(device)\n",
    "    generated_images = decoder(noise)\n",
    "\n",
    "plt.imshow(generated_images[0].detach().cpu().view(-1,4, 200,200)[0].permute(1,2,0))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "Hwc_SFW9UKQa",
    "outputId": "afeb02c1-af26-4d7d-d241-70088de9ed9f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply Model on real image and return z-Vector"
   ],
   "metadata": {
    "id": "_j_c1N1jz6oC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pic = 2 # index of the image in the badge to use\n",
    "batch_idx, data = next(enumerate(train_loader))\n",
    "\n",
    "# the original image\n",
    "plt.imshow(data[pic].detach().cpu().view(-1,4, 200,200)[0].permute(1,2,0))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "6iRNhr_3wkyW",
    "outputId": "94151114-0387-41ca-cc2d-fd19f20db897"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with torch.no_grad():\n",
    "    x_hat, mean, log_var, z = model(data.to(device))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vA7ZGxEBmYen",
    "outputId": "7afb58c3-7dc8-41c8-dffc-710c825bb733"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# the rebuild image\n",
    "plt.imshow(x_hat[pic].detach().cpu().view(-1,4, 200,200)[0].permute(1,2,0))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "I7RnQ0ybmd-3",
    "outputId": "0bc8b065-cac9-42ea-bb2d-eb7b5698cb85"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# latent space of the image\n",
    "z.cpu().numpy()[pic]"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYMIWHTgyzEO",
    "outputId": "b756210c-8ced-4948-add5-8410ef075748"
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "VAE_new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}